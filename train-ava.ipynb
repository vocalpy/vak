{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88ee0dc-7579-40af-9c5d-68bef9b30c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pimienta/Documents/repos/coding/vocalpy/vak-vocalpy/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import datetime\n",
    "import logging\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as lightning\n",
    "import torch.utils.data\n",
    "\n",
    "from src import vak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190f11c3-c115-408e-92de-3d87cd421748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_dur(df: pd.DataFrame, split: str) -> float:\n",
    "    \"\"\"Get duration of a split in a dataset from a pandas DataFrame representing the dataset.\"\"\"\n",
    "    return df[df[\"split\"] == split][\"duration\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166b6c26-ea53-46cc-82df-0f3057c801b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainer(\n",
    "    max_epochs: int,\n",
    "    ckpt_root: str | pathlib.Path,\n",
    "    ckpt_step: int,\n",
    "    log_save_dir: str | pathlib.Path,\n",
    "    device: str = \"cuda\",\n",
    ") -> lightning.Trainer:\n",
    "    \"\"\"Returns an instance of ``lightning.Trainer``\n",
    "    with a default set of callbacks.\n",
    "    Used by ``vak.core`` functions.\"\"\"\n",
    "    # TODO: use accelerator parameter, https://github.com/vocalpy/vak/issues/691\n",
    "    if device == \"cuda\":\n",
    "        accelerator = \"gpu\"\n",
    "    else:\n",
    "        accelerator = \"auto\"\n",
    "\n",
    "    ckpt_callback = lightning.callbacks.ModelCheckpoint(\n",
    "        dirpath=ckpt_root,\n",
    "        filename=\"checkpoint\",\n",
    "        every_n_train_steps=ckpt_step,\n",
    "        save_last=True,\n",
    "        verbose=True,\n",
    "    )\n",
    "    ckpt_callback.CHECKPOINT_NAME_LAST = \"checkpoint\"\n",
    "    ckpt_callback.FILE_EXTENSION = \".pt\"\n",
    "\n",
    "    val_ckpt_callback = lightning.callbacks.ModelCheckpoint(\n",
    "        monitor=\"val_loss\",\n",
    "        dirpath=ckpt_root,\n",
    "        save_top_k=1,\n",
    "        mode=\"min\",\n",
    "        filename=\"min-val-loss-checkpoint\",\n",
    "        auto_insert_metric_name=False,\n",
    "        verbose=True,\n",
    "    )\n",
    "    val_ckpt_callback.FILE_EXTENSION = \".pt\"\n",
    "\n",
    "    callbacks = [\n",
    "        ckpt_callback,\n",
    "        val_ckpt_callback,\n",
    "    ]\n",
    "\n",
    "    logger = lightning.loggers.TensorBoardLogger(save_dir=log_save_dir)\n",
    "\n",
    "    trainer = lightning.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=accelerator,\n",
    "        logger=logger,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf49554-27a4-4baf-b5ae-a2fb9288f4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramPipe(torch.utils.data.Dataset):\n",
    "    \"\"\"Pipeline for loading samples from a dataset of spectrograms\n",
    "    \n",
    "    This is a simplified version of ``vak.datasets.parametric_umap.ParametricUmapInferenceDataset``.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: npt.NDArray,\n",
    "        dataset_df: pd.DataFrame,\n",
    "        transform: Callable | None = None,\n",
    "    ):\n",
    "        self.data = data\n",
    "        self.dataset_df = dataset_df\n",
    "        self.transform = transform\n",
    "\n",
    "    @property\n",
    "    def duration(self):\n",
    "        return self.dataset_df[\"duration\"].sum()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        tmp_x_ind = 0\n",
    "        tmp_item = self.__getitem__(tmp_x_ind)\n",
    "        return tmp_item[\"x\"].shape\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        df_index = self.dataset_df.index[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return {\"x\": x, \"df_index\": df_index}\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataset_path(\n",
    "        cls,\n",
    "        dataset_path: str | pathlib.Path,\n",
    "        split: str,\n",
    "        transform: Callable | None = None,\n",
    "    ):\n",
    "        import vak.datasets  # import here just to make classmethod more explicit\n",
    "\n",
    "        dataset_path = pathlib.Path(dataset_path)\n",
    "        metadata = vak.datasets.parametric_umap.Metadata.from_dataset_path(\n",
    "            dataset_path\n",
    "        )\n",
    "\n",
    "        dataset_csv_path = dataset_path / metadata.dataset_csv_filename\n",
    "        dataset_df = pd.read_csv(dataset_csv_path)\n",
    "        split_df = dataset_df[dataset_df.split == split]\n",
    "\n",
    "        data = np.stack(\n",
    "            [\n",
    "                np.load(dataset_path / spect_path)\n",
    "                for spect_path in split_df.spect_path.values\n",
    "            ]\n",
    "        )\n",
    "        return cls(\n",
    "            data,\n",
    "            split_df,\n",
    "            transform=transform,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c9c5bb-0b94-4649-80f7-db3185e9b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = pathlib.Path(\n",
    "    './tests/data_for_tests/generated/prep/train/audio_cbin_annot_notmat/ConvEncoderUMAP/032312-vak-dimensionality-reduction-dataset-generated-231010_165846/'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1a3d7b-dd9c-4977-9de1-bc31049a06ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = vak.datasets.parametric_umap.Metadata.from_dataset_path(\n",
    "    dataset_path\n",
    ")\n",
    "dataset_csv_path = dataset_path / metadata.dataset_csv_filename\n",
    "dataset_df = pd.read_csv(dataset_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565cdc37-738f-42a1-b65d-4348fd567d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_step = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4a4216-ebba-40ea-ab26-8a5d88211c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = pathlib.Path(\n",
    "    './tests/data_for_tests/generated/results/train/audio_cbin_annot_notmat/AVA'\n",
    ")\n",
    "results_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0ac2fb-fa28-4645-8397-50f5cc1c6bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- load training data  -----------------------------------------------------------------------------\n",
    "\n",
    "# below, if we're going to train network to predict unlabeled segments, then\n",
    "# we need to include a class for those unlabeled segments in labelmap,\n",
    "# the mapping from labelset provided by user to a set of consecutive\n",
    "# integers that the network learns to predict\n",
    "train_dur = get_split_dur(dataset_df, \"train\")\n",
    "print(\n",
    "    f\"Total duration of training split from dataset (in s): {train_dur}\",\n",
    ")\n",
    "\n",
    "\n",
    "train_transform_params = {}\n",
    "transform = vak.transforms.defaults.get_default_transform(\n",
    "    \"ConvEncoderUMAP\", \"train\", train_transform_params\n",
    ")\n",
    "\n",
    "\n",
    "train_dataset_params = {}\n",
    "train_dataset = SpectrogramPipe.from_dataset_path(\n",
    "    dataset_path=dataset_path,\n",
    "    split=\"train\",\n",
    "    transform=transform,\n",
    "    **train_dataset_params,\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=64,\n",
    "    num_workers=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925e06c9-91f8-4614-b56d-56b07e12f564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- load validation set (if there is one) -----------------------------------------------------------\n",
    "\n",
    "\n",
    "val_transform_params = {}\n",
    "transform = vak.transforms.defaults.get_default_transform(\n",
    "    \"ConvEncoderUMAP\", \"eval\", val_transform_params\n",
    ")\n",
    "val_dataset_params = {}\n",
    "val_dataset = SpectrogramPipe.from_dataset_path(\n",
    "    dataset_path=dataset_path,\n",
    "    split=\"val\",\n",
    "    transform=transform,\n",
    "    **val_dataset_params,\n",
    ")\n",
    "print(\n",
    "    f\"Duration of ParametricUMAPDataset used for validation, in seconds: {val_dataset.duration}\",\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=64,\n",
    "    num_workers=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb39ce3-72db-4b53-b4b9-a08b449b37d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = vak.common.device.get_default()\n",
    "\n",
    "model = vak.models.get(\n",
    "    \"AVA\",\n",
    "    config={\"network\": {}, \"optimizer\": {\"lr\": 0.001}},\n",
    "    input_shape=train_dataset.shape,\n",
    ")\n",
    "\n",
    "results_model_root = results_path.joinpath(\"AVA\")\n",
    "results_model_root.mkdir(exist_ok=True)\n",
    "ckpt_root = results_model_root.joinpath(\"checkpoints\")\n",
    "ckpt_root.mkdir(exist_ok=True)\n",
    "\n",
    "trainer = get_trainer(\n",
    "    max_epochs=50,\n",
    "    log_save_dir=results_model_root,\n",
    "    device=device,\n",
    "    ckpt_root=ckpt_root,\n",
    "    ckpt_step=250,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe993c8b-4571-4892-b645-91d778df2fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    model=model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
