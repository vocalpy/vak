# PREP: options for preparing dataset
[PREP]
# dataset_type: corresponds to the model family such as "frame classification" or "parametric umap"
dataset_type = "frame classification"
# input_type: input to model, either audio ("audio") or spectrogram ("spect")
input_type = "spect"
# data_dir: directory with data to use when preparing dataset
data_dir = "/PATH/TO/DATA/032312"
# output_dir: directory where dataset will be created (as a sub-directory within output_dir)
output_dir = "/PATH/TO/DATA/vak/prep/predict"
# audio_format: format of audio, either wav or cbin
audio_format = "wav"
# note that for predictions we don't need to specify labelset or annot_format
# note also that we do not specify train_dur / val_dur / test_dur;
# all data found in `data_dir` will be assigned to a "predict split" instead

# SPECT_PARAMS: parameters for computing spectrograms
[SPECT_PARAMS]
# fft_size: size of window used for Fast Fourier Transform, in number of samples
fft_size = 512
# step_size: size of step to take when computing spectra with FFT for spectrogram
# also known as hop size
step_size = 64

# PREDICT: options for generating predictions with a trained model
[PREDICT]
# model: the string name of the model. must be a name within `vak.models` or added e.g. with `vak.model.decorators.model`
model = "TweetyNet"
# labelmap_path: path to file that maps from outputs of model (integers) to text labels in annotations;
# this is used when generating predictions
labelmap_path = "/PATH/TO/DATA/vak/train/RESULTS_TIMESTAMP/labelmap.json"
# checkpoint_path: path to checkpoint
checkpoint_path = "/PATH/TO/DATA/vak/train/RESULTS_TIMESTAMP/TweetyNet/checkpoints/max-val-acc-checkpoint.pt"
# spect_scaler_path: path to file containing SpectScaler that was fit to training set
# We want to transform the data we predict on in the exact same way
spect_scaler_path = "/PATH/TO/DATA/vak/train/RESULTS_TIMESTAMP/StandardizeSpect"
# batch_size
# for predictions with a frame classification model, this should always be 1
# and will be ignored if it's not
batch_size = 1
# num_workers: number of workers to use when loading data with multiprocessing
num_workers = 4
# device: name of device to run model on, one of "cuda", "cpu"
device = "cuda"
# output_dir: directory where output should be saved, as a sub-directory within `output_dir`
output_dir = "/PATH/TO/DATA/vak/prep/predict"
# annot_csv_filename
annot_csv_filename = "gy6or6.032312.annot.csv"
# majority_vote: post-processing transformation that takes majority vote within segments that
# do not have the 'unlabeled' class label. Only applied if `majority_vote` is `true`
# (default is false).
majority_vote = true
# min_segment_dur: post-processing transformation removes any segments
# with a duration shorter than `min_segment_dur` that do not have the 'unlabeled' class.
# Only applied if this option is specified.
min_segment_dur = 0.01

# transform_params: parameters used when transforming data
# for a frame classification model, we use FrameDataset with the eval_item_transform,
# that reshapes batches into consecutive adjacent windows with a specific `window_size`
[PREDICT.transform_params]
window_size = 176

# NOte we do not specify any options for the network, and just use the defaults