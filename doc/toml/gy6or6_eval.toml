[vak.prep]
# dataset_type: corresponds to the model family such as "frame classification" or "parametric umap"
dataset_type = "frame classification"
# input_type: input to model, either audio ("audio") or spectrogram ("spect")
input_type = "spect"
# data_dir: directory with data to use when preparing dataset
data_dir = "/PATH/TO/FOLDER/gy6or6/032212"
# output_dir: directory where dataset will be created (as a sub-directory within output_dir)
output_dir = "/PATH/TO/FOLDER/prep/train"
# audio_format: format of audio, either wav or cbin
audio_format = "wav"
# annot_format: format of annotations
annot_format = "simple-seq"
# labelset: string or array with unique set of labels used in annotations
labelset = "iabcdefghjk"
# train_dur: duration of training split in dataset, in seconds
train_dur = 50
# val_dur: duration of validation split in dataset, in seconds
val_dur = 15

# SPECT_PARAMS: parameters for computing spectrograms
[vak.prep.spect_params]
# fft_size: size of window used for Fast Fourier Transform, in number of samples
fft_size = 512
# step_size: size of step to take when computing spectra with FFT for spectrogram
# also known as hop size
step_size = 64

# EVAL: options for evaluating a trained model. This is done using the "test" split.
[vak.eval]
# checkpoint_path: path to saved model checkpoint
checkpoint_path = "/PATH/TO/FOLDER/results/train/RESULTS_TIMESTAMP/TweetyNet/checkpoints/max-val-acc-checkpoint.pt"
# labelmap_path: path to file that maps from outputs of model (integers) to text labels in annotations;
# this is used when generating predictions
labelmap_path = "/PATH/TO/FOLDER/results/train/RESULTS_TIMESTAMP/labelmap.json"
# frames_standardizer_path: path to file containing SpectScaler that was fit to training set
# We want to transform the data we predict on in the exact same way
frames_standardizer_path = "/PATH/TO/FOLDER/results/train/RESULTS_TIMESTAMP/StandardizeSpect"
# batch_size
# for predictions with a frame classification model, this should always be 1
# and will be ignored if it's not
batch_size = 11
# num_workers: number of workers to use when loading data with multiprocessing
num_workers = 16
# device: name of device to run model on, one of "cuda", "cpu"

# output_dir: directory where output should be saved, as a sub-directory within `output_dir`
output_dir = "/PATH/TO/FOLDER/results/eval"
# dataset_path : path to dataset created by prep
# ADD THE dataset_path OPTION FROM THE TRAIN FILE HERE (we already created a test split when we ran `vak prep` with that config)

# EVAL.post_tfm_kwargs: options for post-processing
[vak.eval.post_tfm_kwargs]
# both these transforms require that there is an "unlabeled" label,
# and they will only be applied to segments that are bordered on both sides
# by the "unlabeled" label.
# Such a label class is added by default by vak.
# majority_vote: post-processing transformation that takes majority vote within segments that
# do not have the 'unlabeled' class label. Only applied if `majority_vote` is `true`
# (default is false).
majority_vote = true
# min_segment_dur: post-processing transformation removes any segments
# with a duration shorter than `min_segment_dur` that do not have the 'unlabeled' class.
# Only applied if this option is specified.
min_segment_dur = 0.02

# dataset.params = parameters used for datasets
# for a frame classification model, we use dataset classes with a specific `window_size`
[vak.eval.dataset.params]
window_size = 176

# Note we do not specify any options for the model, and just use the defaults
# We need to put this table here though so we know which model we are using
[vak.eval.model.TweetyNet]

# this sub-table configures the `lightning.pytorch.Trainer`
[vak.eval.trainer]
# setting to 'gpu' means "train models on 'gpu' (not 'cpu')"
accelerator = "gpu"
# use the first GPU (numbering starts from 0)
devices = [0]
